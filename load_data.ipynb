{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caa52c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#从transfer_date列筛选年份为2000-2024\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\".\\\\transfermarket_data\\\\transfers.csv\")  # 原始表\n",
    "\n",
    "date_col = \"transfer_date\"\n",
    "\n",
    "# 解析日期 -> 年\n",
    "df[\"year\"] = pd.to_datetime(df[date_col].astype(str), errors=\"coerce\").dt.year\n",
    "\n",
    "# 过滤 2000..2024（含边界）\n",
    "out = df[df[\"year\"].between(2000, 2024, inclusive=\"both\")].copy()\n",
    "\n",
    "# 保存\n",
    "out.to_csv(\"transfers_2000_2024.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c46aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# club_transfer_graph.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "按步骤构建“俱乐部为节点、人数为权重的有向图”，并导出边表、GEXF 和示意图。\n",
    "\n",
    "步骤目录：\n",
    "0) 导入 & 参数\n",
    "1) 读取 CSV\n",
    "2) 自动识别关键列\n",
    "3) 可选的时间过滤（year 或 transfer_date）\n",
    "4) 选取并清洗 (from_club, to_club, player_key)\n",
    "5) 统计加权有向边（weight & unique_players）\n",
    "6) 构建 NetworkX DiGraph & 计算强度\n",
    "7) 导出：边表 CSV、GEXF\n",
    "8) 可视化（选取活跃节点 + 较粗的边）\n",
    "9) 打印/保存 Top 榜单\n",
    "\"\"\"\n",
    "\n",
    "# --------------------------- 0) 导入 & 参数 ---------------------------\n",
    "import argparse\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--csv\", required=True, help=\"转会记录 CSV 路径\")\n",
    "    p.add_argument(\"--out_dir\", default=\"out_graph\", help=\"输出目录\")\n",
    "    # 过滤/取数参数\n",
    "    p.add_argument(\"--year_min\", type=int, default=None, help=\"最小年份（包含）\")\n",
    "    p.add_argument(\"--year_max\", type=int, default=None, help=\"最大年份（包含）\")\n",
    "    p.add_argument(\"--remove_without_club\", action=\"store_true\", help=\"过滤名称为 'Without Club' 的记录\")\n",
    "    p.add_argument(\"--weight_mode\", choices=[\"events\", \"unique\"], default=\"events\",\n",
    "                   help=\"权重定义：events=事件数；unique=唯一球员数\")\n",
    "    # 可视化参数（子图抽样）\n",
    "    p.add_argument(\"--top_k\", type=int, default=40, help=\"总强度最高的前 K 个节点用于画图\")\n",
    "    p.add_argument(\"--edge_quantile\", type=float, default=0.60, help=\"边权重分位数阈值（0~1）用于筛边\")\n",
    "    p.add_argument(\"--label_top_n\", type=int, default=15, help=\"给强度前 N 的节点打标签\")\n",
    "    return p.parse_args()\n",
    "\n",
    "\n",
    "# --------------------------- 1) 读取 CSV ---------------------------\n",
    "def read_csv(csv_path: Path) -> pd.DataFrame:\n",
    "    try:\n",
    "        return pd.read_csv(csv_path, low_memory=False)\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(csv_path, low_memory=False, encoding=\"latin1\")\n",
    "\n",
    "\n",
    "# --------------------------- 2) 自动识别关键列 ---------------------------\n",
    "def normalize_col(col: str) -> str:\n",
    "    col = unicodedata.normalize(\"NFKC\", str(col)).strip().lower()\n",
    "    safe = []\n",
    "    for ch in col:\n",
    "        safe.append(ch if ch.isalnum() else \"_\")\n",
    "    return \"\".join(safe)\n",
    "\n",
    "\n",
    "def pick_col(cols_norm_map, candidates):\n",
    "    for raw, norm in cols_norm_map.items():\n",
    "        for cand in candidates:\n",
    "            # 允许轻微噪声：精确 / 结尾匹配 / 包含\n",
    "            if norm == cand or norm.endswith(\"_\" + cand) or cand in norm:\n",
    "                return raw\n",
    "    return None\n",
    "\n",
    "\n",
    "def detect_columns(df: pd.DataFrame):\n",
    "    cols_norm = {c: normalize_col(c) for c in df.columns}\n",
    "\n",
    "    from_candidates = [\n",
    "        \"from_club\",\"club_from\",\"fromteam\",\"fromclub\",\"from\",\"source_club\",\"source\",\n",
    "        \"selling_club\",\"seller_club\",\"prev_club\",\"club_name_from\",\"from_team\",\n",
    "        \"from_club_id\",\"from_club_name\"\n",
    "    ]\n",
    "    to_candidates = [\n",
    "        \"to_club\",\"club_to\",\"toteam\",\"toclub\",\"to\",\"target_club\",\"target\",\n",
    "        \"buying_club\",\"buyer_club\",\"next_club\",\"club_name_to\",\"to_team\",\n",
    "        \"to_club_id\",\"to_club_name\"\n",
    "    ]\n",
    "    player_id_candidates = [\"player_id\",\"id\",\"tm_player_id\",\"sofifa_id\",\"person_id\",\"player\"]\n",
    "    player_name_candidates = [\"player_name\",\"name\",\"player_full_name\"]\n",
    "    date_candidates = [\"year\",\"transfer_date\",\"date\",\"transfered\",\"transferred\",\"move_date\",\"deal_date\",\"transfer_season\",\"season\"]\n",
    "\n",
    "    col_from = pick_col(cols_norm, from_candidates)\n",
    "    col_to   = pick_col(cols_norm, to_candidates)\n",
    "    col_pid  = pick_col(cols_norm, player_id_candidates) or pick_col(cols_norm, player_name_candidates)\n",
    "    col_date = pick_col(cols_norm, date_candidates)\n",
    "\n",
    "    # 若同时存在 name 和 id，优先 id 作为 player_key\n",
    "    raw_cols = df.columns\n",
    "    if \"player_id\" in raw_cols:\n",
    "        col_pid = \"player_id\"\n",
    "    if \"from_club_name\" in raw_cols:\n",
    "        col_from = \"from_club_name\"\n",
    "    if \"to_club_name\" in raw_cols:\n",
    "        col_to = \"to_club_name\"\n",
    "\n",
    "    return dict(from_col=col_from, to_col=col_to, player_key_col=col_pid, date_col=col_date)\n",
    "\n",
    "\n",
    "# --------------------------- 3) 可选的时间过滤 ---------------------------\n",
    "def filter_by_time(df: pd.DataFrame, col_date: str, year_min: int, year_max: int) -> pd.DataFrame:\n",
    "    if year_min is None and year_max is None:\n",
    "        return df\n",
    "\n",
    "    df2 = df.copy()\n",
    "    # 优先 year 列；没有则从 transfer_date 解析\n",
    "    if \"year\" in df2.columns:\n",
    "        df2[\"__year__\"] = pd.to_numeric(df2[\"year\"], errors=\"coerce\")\n",
    "    elif col_date and col_date in df2.columns:\n",
    "        dt = pd.to_datetime(df2[col_date], errors=\"coerce\")\n",
    "        df2[\"__year__\"] = dt.dt.year\n",
    "    else:\n",
    "        df2[\"__year__\"] = np.nan  # 无法过滤\n",
    "\n",
    "    if year_min is not None:\n",
    "        df2 = df2[df2[\"__year__\"] >= year_min]\n",
    "    if year_max is not None:\n",
    "        df2 = df2[df2[\"__year__\"] <= year_max]\n",
    "    df2 = df2.drop(columns=[\"__year__\"])\n",
    "    return df2\n",
    "\n",
    "\n",
    "# --------------------------- 4) 选取并清洗列 ---------------------------\n",
    "def build_work_df(df: pd.DataFrame, cols: dict, remove_without_club: bool) -> pd.DataFrame:\n",
    "    for k in [\"from_col\",\"to_col\",\"player_key_col\"]:\n",
    "        if not cols.get(k):\n",
    "            raise ValueError(f\"无法识别列：{k}，请检查 CSV 列名。\")\n",
    "\n",
    "    work = df[[cols[\"from_col\"], cols[\"to_col\"], cols[\"player_key_col\"]]].copy()\n",
    "    work.rename(columns={\n",
    "        cols[\"from_col\"]: \"from_club\",\n",
    "        cols[\"to_col\"]: \"to_club\",\n",
    "        cols[\"player_key_col\"]: \"player_key\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    # 丢缺失 & 空值\n",
    "    work = work.dropna(subset=[\"from_club\",\"to_club\",\"player_key\"])\n",
    "    work = work[(work[\"from_club\"].astype(str).str.len() > 0) &\n",
    "                (work[\"to_club\"].astype(str).str.len() > 0)]\n",
    "\n",
    "    # 丢自环\n",
    "    work = work[work[\"from_club\"] != work[\"to_club\"]]\n",
    "\n",
    "    # 可选：过滤 Without Club\n",
    "    if remove_without_club:\n",
    "        work = work[(work[\"from_club\"] != \"Without Club\") & (work[\"to_club\"] != \"Without Club\")]\n",
    "\n",
    "    return work\n",
    "\n",
    "\n",
    "# --------------------------- 5) 统计加权有向边 ---------------------------\n",
    "def aggregate_edges(work: pd.DataFrame, weight_mode: str) -> pd.DataFrame:\n",
    "    if weight_mode == \"events\":\n",
    "        agg_weight = (\"player_key\", \"size\")  # 事件数\n",
    "    else:\n",
    "        agg_weight = (\"player_key\", pd.Series.nunique)  # 唯一球员数\n",
    "\n",
    "    edge_counts = (\n",
    "        work.groupby([\"from_club\",\"to_club\"])\n",
    "            .agg(weight=agg_weight,\n",
    "                 unique_players=(\"player_key\", pd.Series.nunique))\n",
    "            .reset_index()\n",
    "            .sort_values(\"weight\", ascending=False)\n",
    "    )\n",
    "    return edge_counts\n",
    "\n",
    "\n",
    "# --------------------------- 6) 构图 & 强度 ---------------------------\n",
    "def build_graph(edge_counts: pd.DataFrame) -> tuple[nx.DiGraph, dict, dict, dict]:\n",
    "    G = nx.DiGraph()\n",
    "    for _, r in edge_counts.iterrows():\n",
    "        G.add_edge(r[\"from_club\"], r[\"to_club\"],\n",
    "                   weight=int(r[\"weight\"]),\n",
    "                   unique_players=int(r[\"unique_players\"]))\n",
    "    out_strength = dict(G.out_degree(weight=\"weight\"))\n",
    "    in_strength  = dict(G.in_degree(weight=\"weight\"))\n",
    "    total_strength = {n: out_strength.get(n, 0) + in_strength.get(n, 0) for n in G.nodes()}\n",
    "    return G, out_strength, in_strength, total_strength\n",
    "\n",
    "\n",
    "# --------------------------- 7) 导出 CSV & GEXF ---------------------------\n",
    "def export_artifacts(edge_counts: pd.DataFrame, G: nx.DiGraph, out_dir: Path):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    edges_csv = out_dir / \"global_transfers_edges.csv\"\n",
    "    gexf_path = out_dir / \"club_transfers_graph.gexf\"\n",
    "\n",
    "    edge_counts.to_csv(edges_csv, index=False)\n",
    "    nx.write_gexf(G, gexf_path)\n",
    "    return edges_csv, gexf_path\n",
    "\n",
    "\n",
    "# --------------------------- 8) 可视化（活跃子图） ---------------------------\n",
    "def visualize_graph(G: nx.DiGraph, total_strength: dict,\n",
    "                    out_dir: Path, top_k=40, edge_quantile=0.60, label_top_n=15):\n",
    "    # 选择 Top-K 节点\n",
    "    nodes_sorted = sorted(total_strength.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_nodes = [n for n, _ in nodes_sorted[:min(top_k, len(nodes_sorted))]]\n",
    "    H = G.subgraph(top_nodes).copy()\n",
    "\n",
    "    # 筛边：按权重分位数与 3 取 max\n",
    "    if H.number_of_edges() > 0:\n",
    "        weights = [d[\"weight\"] for _, _, d in H.edges(data=True)]\n",
    "        w_thr = max(3, int(np.quantile(weights, edge_quantile))) if len(weights) else 1\n",
    "        strong_edges = [(u, v) for u, v, d in H.edges(data=True) if d.get(\"weight\", 1) >= w_thr]\n",
    "        H = H.edge_subgraph(strong_edges).copy()\n",
    "\n",
    "    if H.number_of_nodes() == 0:\n",
    "        print(\"筛选后子图为空，跳过可视化。\")\n",
    "        return None\n",
    "\n",
    "    # 布局\n",
    "    k = 0.6 / math.sqrt(max(1, H.number_of_nodes()))\n",
    "    pos = nx.spring_layout(H, seed=42, k=k)\n",
    "\n",
    "    # 节点大小 & 标签\n",
    "    node_sizes = [80 + 2.0 * total_strength.get(n, 0) for n in H.nodes()]\n",
    "    labels = {}\n",
    "    for n, _s in sorted({n: total_strength.get(n, 0) for n in H.nodes()}.items(),\n",
    "                        key=lambda x: x[1], reverse=True)[:label_top_n]:\n",
    "        labels[n] = n\n",
    "\n",
    "    # 边宽度归一\n",
    "    allw = [d[\"weight\"] for _, _, d in H.edges(data=True)]\n",
    "    if allw:\n",
    "        w_min, w_max = min(allw), max(allw)\n",
    "        denom = (w_max - w_min) if (w_max - w_min) > 0 else 1\n",
    "        edge_widths = [1.0 + 3.0 * (d[\"weight\"] - w_min) / denom for _, _, d in H.edges(data=True)]\n",
    "    else:\n",
    "        edge_widths = [1.0] * H.number_of_edges()\n",
    "\n",
    "    # 画图\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    nx.draw_networkx_nodes(H, pos, node_size=node_sizes)\n",
    "    nx.draw_networkx_edges(H, pos, width=edge_widths, arrows=True, arrowstyle='-|>', arrowsize=10)\n",
    "    nx.draw_networkx_labels(H, pos, labels=labels, font_size=9)\n",
    "    plt.axis(\"off\")\n",
    "    out_png = out_dir / \"club_transfers_network.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=180, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return out_png\n",
    "\n",
    "\n",
    "# --------------------------- 9) Top 榜单 ---------------------------\n",
    "def export_tops(edge_counts: pd.DataFrame,\n",
    "                out_strength: dict, in_strength: dict,\n",
    "                out_dir: Path, k=20):\n",
    "    top_edges = edge_counts.head(25)\n",
    "    top_out = pd.DataFrame(sorted(out_strength.items(), key=lambda x: x[1], reverse=True)[:k],\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "football",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
